{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f0dcf50-8ddd-4512-9eed-ece051f11c4a",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60011ab-f4fe-44f3-bdf8-1cc7e10ee5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset,  Subset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba79b7-89ef-4f44-9f49-77facd2a8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using CUDA.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d383585a-d0d0-473e-9d02-8469c0d043cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "folder_path = 'video_frames/'\n",
    "\n",
    "image_paths = os.listdir(folder_path)\n",
    "image_paths = [folder_path + img_path for img_path in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464c74f-7451-471a-aa23-1bf28369d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "y = []\n",
    "for img in image_paths:\n",
    "    y.append( cv2.imread(img, cv2.IMREAD_GRAYSCALE) )\n",
    "\n",
    "y = np.array(y)\n",
    "X = np.arange(y.shape[0])\n",
    "\n",
    "X = torch.tensor(X)\n",
    "#X = nn.functional.one_hot(X, num_classes=y.shape[0]).float()\n",
    "y = torch.tensor(y).float()\n",
    "y = y/255 # ensures that values scale between 0 and 1.\n",
    "\n",
    "#mean = 0.45848998\n",
    "#std = 0.4895395\n",
    "\n",
    "#normalize = transforms.Normalize(mean=mean, std=std)\n",
    "#y = normalize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa2f43-4fb5-47ad-b8c0-f997b73d58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y.shape[0]\n",
    "output_dimensions = y[0].shape\n",
    "print(f\"Num classes: {num_classes}\")\n",
    "print(f\"Output dimensions: {output_dimensions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62202ba-d225-427e-8019-f7b7c71ae760",
   "metadata": {},
   "source": [
    "### Fully connected NN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a55bbf-889e-4a07-bf0e-cb6625f2a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=256, num_classes=num_classes):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # FC layer for feature mapping\n",
    "        self.fc = nn.Linear(num_classes, latent_dim * 3 * 4)\n",
    "\n",
    "        # Deconvolution layers\n",
    "        self.deconv_block1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 100, \n",
    "                               kernel_size=5, stride=5, padding=0),\n",
    "            nn.BatchNorm2d(100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.deconv_block2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 100, \n",
    "                               kernel_size=3, stride=3, padding=0),\n",
    "            nn.BatchNorm2d(100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.deconv_block3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 100, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.deconv_block4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 100,\n",
    "                               kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(100),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.deconv_block5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 1,\n",
    "                               kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First convolution\n",
    "        x = nn.functional.one_hot(x, num_classes=self.num_classes).float()\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, self.latent_dim, 3, 4)\n",
    "        \n",
    "        x1 = self.deconv_block1(x)\n",
    "        x2 = self.deconv_block2(x1)\n",
    "        x2 = x2 + torch.sum(x)/12  # skip connection\n",
    "        \n",
    "        x3 = self.deconv_block3(x2)\n",
    "        x4 = self.deconv_block4(x3)\n",
    "        x4 = x4 + torch.sum(x)/12 # skip connection\n",
    "        \n",
    "        x5 = self.deconv_block5(x4)\n",
    "        output = x5.view(-1, 180, 240)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6594f2f-4e41-44cb-9819-5a13d21931ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Conv_Decoder()\n",
    "model = torch.load('models/Conv_Decoder_Clean.pkl', weights_only=False)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c31211-1f6d-4cbf-b6a1-70ff9bddd184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "decay_1 = 0.8 # Decay of moving average of gradient\n",
    "decay_2 = 0.999 # Decay of moving average of squared gradient\n",
    "\n",
    "lr = 0.00001\n",
    "weight_decay = 0.0\n",
    "\n",
    "#lr_decay_rate = 0.99\n",
    "\n",
    "# Separate bias parameters and non-bias parameters\n",
    "bias_params = [param for name, param in model.named_parameters() if 'bias' in name]\n",
    "non_bias_params = [param for name, param in model.named_parameters() if 'bias' not in name]\n",
    "factor = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ae32d-dcf0-43b0-91ac-34042f72658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function, Optimizer and Scheduler\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': non_bias_params, 'lr': lr}, \n",
    "    {'params': bias_params, 'lr': lr * factor}  # increase bias learning rate by factor\n",
    "], betas=(decay_1, decay_2), weight_decay=weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3dd411-d6ab-49d4-a62f-454da8b4427a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "X = X.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96694f66-e22f-43e4-93ff-5e1f1110db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_device = next(model.parameters()).device\n",
    "inputs_device = X.device\n",
    "labels_device = y.device\n",
    "\n",
    "print(model_device)\n",
    "print(inputs_device)\n",
    "print(labels_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217652b-d970-4482-93bd-52ef5fd9055b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X[2000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b5b2e-bc3f-4889-9d60-334419b2e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(torch.tensor(0, dtype=torch.long).to(device))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896c69e-1108-4355-8cb7-d8e1c6cdb0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate randomized sequential indices\n",
    "seq_length = 6571\n",
    "start_idx = np.random.randint(0, seq_length)  # Random start\n",
    "indices = np.arange(start_idx, start_idx + seq_length) % seq_length  # Wrap around\n",
    "\n",
    "# Create a Subset dataset with randomized sequence start\n",
    "shuffled_dataset = Subset(TensorDataset(X, y), indices.tolist())\n",
    "\n",
    "dataloader = DataLoader(shuffled_dataset, batch_size=3, shuffle=False) # both train and test (deliberate overfit) - alternating shuffle\n",
    "\n",
    "num_epochs = 500\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eda7b4-298b-4b4a-a176-048147ce6964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training loop (Repeated many times until convergeance)\n",
    "loss_values = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train() # Set to train mode\n",
    "    for inputs, labels in dataloader:\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Feed-forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Add loss\n",
    "        batch_loss = loss.item()\n",
    "        running_loss += batch_loss\n",
    "        loss_values.append(batch_loss)\n",
    "    \n",
    "    # Average loss for the epoch\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "\n",
    "    # Update the learning rate at the end of each epoch\n",
    "    scheduler.step()\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f6adc-41c2-4a3c-b06f-f866cabf856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves model\n",
    "torch.save(model, 'models/Conv_Decoder_Clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29610f2c-cd6c-434d-8280-2e57a88bc841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
